{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"preprocessing.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Hw1r1gOV-gT6","colab_type":"text"},"source":["**Processing notebook** <br>\n","This notebook preprocesses textual data. It loads the data (from the clickbait-challenge site) and does the following: specifically:\n","- remove stop words <br>\n","- stem using a porter stemmer <br>\n","- remove HTML tags <br>\n","- trim white saces <br>\n","- replace numbers with special [N] token <br>\n","- tokenize  <br>\n"]},{"cell_type":"code","metadata":{"id":"6_DxiaTd-gT8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"outputId":"461f1112-d1ae-4b68-c9f0-0bae30da0e8d","executionInfo":{"status":"ok","timestamp":1575313424714,"user_tz":300,"elapsed":488,"user":{"displayName":"Yuansheng Xie","photoUrl":"","userId":"02952600350336082848"}}},"source":["import time\n","import re\n","import numpy as np\n","import pandas as pd\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords \n","from nltk.stem import PorterStemmer \n","from nltk.tokenize import word_tokenize \n","import warnings\n","warnings.filterwarnings('ignore')\n","np.random.seed(42)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4PBGdv4GGSjE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0febfacc-b102-4b9a-8d4d-e81798a53a85","executionInfo":{"status":"ok","timestamp":1575315145283,"user_tz":300,"elapsed":382,"user":{"displayName":"Yuansheng Xie","photoUrl":"","userId":"02952600350336082848"}}},"source":[""],"execution_count":18,"outputs":[{"output_type":"stream","text":["[0. 1. 1.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iFJL6yK7-gT_","colab_type":"code","colab":{}},"source":["#a simple function to concatenate a list of strings into one string\n","def combine_into_one_string(list_of_strings):\n","    x = ''\n","    for s in list_of_strings:\n","        x += s\n","    return x\n","\n","#function for preprocessing according to techniques in papers read\n","def prepare_text(text):\n","    stop_words = set(stopwords.words('english')) \n","    porter_stemmer = PorterStemmer() \n","\n","    HTML_tags = re.compile(r'<.+?>')\n","    NON_ALPHA_NUMERIC = re.compile(r'\\W+')\n","    numbers = re.compile(r'\\d+')\n","    whitespace = re.compile(r'\\s+')\n","    \n","    preped_text = ''\n","    word_tokens = word_tokenize(text) \n","    for token in word_tokens:\n","        \n","        token = token.lower()\n","        token = token.replace('–', '-')\n","        token = token.replace(\"'\", ' ')\n","        token = HTML_tags.sub(' ', text)\n","        token = NON_ALPHA_NUMERIC.sub(' ', text)\n","        token = porter_stemmer.stem(token)\n","        if token not in stop_words:\n","            preped_text += token\n","        preped_text = numbers.sub(' [N]', preped_text)\n","        preped_text = whitespace.sub(' ', preped_text).strip()\n","\n","    return preped_text\n","\n","start_time = time.time()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FtxKEhMl-gUB","colab_type":"code","colab":{},"outputId":"2c6f33f8-d526-4e6a-a302-5e332c79df69"},"source":["start_time = time.time()\n","\n","#load first raw data file\n","df_truth1 = pd.read_json('data/raw/truth1.jsonl', lines='True')\n","df_instances1 = pd.read_json('data/raw/instances1.jsonl', lines='True')\n","df_1 = df_instances1.merge(df_truth1, how='inner', on='id')\n","\n","#load second raw data file\n","df_truth2 = pd.read_json('data/raw/truth2.jsonl', lines='True')\n","df_instances2 = pd.read_json('data/raw/instances2.jsonl', lines='True')\n","df_2 = df_instances2.merge(df_truth2, how='inner', on='id')\n","\n","#concatenate\n","df_final = pd.concat([df_1, df_2])\n","\n","\n","\n","#edit this array to process features\n","features= ['postText', 'targetKeywords'] \n","for feature in features:\n","     feature_start_time = time.time()\n","     df_final[feature] = df_final[feature].transform(func=combine_into_one_string)\n","     df_final[feature] = df_final[feature].transform(func=prepare_text)\n","     print(f'Finished preprocessing {feature}. Total time for preprocessing {feature} was {time.time() - feature_start_time}s')\n","    \n","print(f'Total preprocess time: {time.time()-start_time}s')\n","\n","print(df_final.head())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Finished preprocessing postText. Total time for preprocessing postText was 23.023833751678467s\n","Finished preprocessing targetKeywords. Total time for preprocessing targetKeywords was 73.52147960662842s\n","Total preprocess time: 97.62794876098633s\n","                   id                       postMedia  \\\n","0  608310377143799808                              []   \n","1  609297109095972864  [media/609297109095972864.jpg]   \n","2  609504474621612032                              []   \n","3  609748367049105408                              []   \n","4  608688782821453824  [media/608688782821453825.jpg]   \n","\n","                                            postText  \\\n","0  apple s ios [N] app thinning feature will give...   \n","1  rt kenbrown [N] emerging market investors are ...   \n","2  u s soccer should start answering tough questi...   \n","3  how theme parks like disney world left the mid...   \n","4  could light bulbs hurt your health one company...   \n","\n","                    postTimestamp  \\\n","0  Tue Jun 09 16:31:10 +0000 2015   \n","1  Fri Jun 12 09:52:05 +0000 2015   \n","2  Fri Jun 12 23:36:05 +0000 2015   \n","3  Sat Jun 13 15:45:13 +0000 2015   \n","4  Wed Jun 10 17:34:49 +0000 2015   \n","\n","                                      targetCaptions  \\\n","0  ['App thinning' will be supported on Apple's i...   \n","1  [Stocks Fall as Investors Watch Central Banks,...   \n","2  [US to vote for Ali in FIFA election and not B...   \n","3  [Some 1,000 persons turned out in Albuquerque,...   \n","4  [Electric lights have made the world safer and...   \n","\n","                                   targetDescription  \\\n","0  'App thinning' will be supported on Apple's iO...   \n","1  Global investors have yanked $9.3 billion from...   \n","2  A U.S. Senator's scathing letter questioned U....   \n","3  America's top family vacation spots, like the ...   \n","4  One company will put a health notice on all th...   \n","\n","                                      targetKeywords  \\\n","0  apple gives gigabytes ios [N] app thinning fea...   \n","1  emerging market emerging markets em flows em i...   \n","2                                                      \n","3  disney disney world disney ticket prices disne...   \n","4  health should there be warning labels on your ...   \n","\n","                                    targetParagraphs  \\\n","0  [Paying for a 64GB phone only to discover that...   \n","1  [Emerging markets are out of favor., Global in...   \n","2  [WINNIPEG, Manitoba â€“ The bubble U.S. Soccer...   \n","3  [When Walt Disney World opened in an Orlando s...   \n","4  [(CNN)The light bulb always makes the world's ...   \n","\n","                                         targetTitle    truthClass  \\\n","0  Apple gives back gigabytes: iOS 9 'app thinnin...  no-clickbait   \n","1  Emerging Markets Suffer Largest Outflow in Sev...  no-clickbait   \n","2  U.S. Soccer should start answering tough quest...     clickbait   \n","3  How theme parks like Disney World left the mid...  no-clickbait   \n","4                 Warning labels on your light bulbs     clickbait   \n","\n","                                      truthJudgments  truthMean  truthMedian  \\\n","0    [0.0, 0.6666667, 0.0, 0.33333334000000003, 0.0]   0.200000     0.000000   \n","1                    [0.6666667, 0.0, 0.0, 0.0, 0.0]   0.133333     0.000000   \n","2  [0.33333334000000003, 0.6666667, 1.0, 0.0, 0.6...   0.533333     0.666667   \n","3  [1.0, 0.0, 0.33333334000000003, 0.333333340000...   0.466667     0.333333   \n","4  [1.0, 0.33333334000000003, 0.6666667, 0.333333...   0.666667     0.666667   \n","\n","   truthMode  \n","0   0.000000  \n","1   0.000000  \n","2   0.666667  \n","3   0.333333  \n","4   1.000000  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cHXbIYjd-gUF","colab_type":"code","colab":{}},"source":["#output data\n","df_final.to_csv('data/prepped/prepped.csv', index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5XPk6BmQ-gUI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}